{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c7514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Suppress tqdm warning about IProgress (ipywidgets) - progress bars will still work\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='tqdm')\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "\n",
    "# Note: transformers library is imported in the model setup cell\n",
    "# to keep imports organized by functionality\n",
    "# \n",
    "# Note: If you want enhanced progress bars in Jupyter, install ipywidgets:\n",
    "#   pip install ipywidgets\n",
    "#   jupyter nbextension enable --py widgetsnbextension  # for classic notebook\n",
    "#   or for JupyterLab: jupyter labextension install @jupyter-widgets/jupyterlab-manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5aceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert grayscale to RGB for pretrained models (which expect 3 channels)\n",
    "# TissueMNIST is grayscale (1 channel), so we repeat it 3 times\n",
    "# Use ImageNet normalization for pretrained models\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.shape[0] == 1 else x),  # Convert 1 channel to 3\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "])\n",
    "\n",
    "data_flag = 'tissuemnist'\n",
    "# data_flag = 'breastmnist'\n",
    "download = False\n",
    "\n",
    "# Training hyperparameters - same for both CNN and Swin Transformer\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 128\n",
    "lr = 0.001  # Learning rate for transfer learning\n",
    "USE_PRETRAINED = True  # Use ImageNet pretrained weights for both models\n",
    "\n",
    "# Model saving configuration\n",
    "SAVE_MODELS = True  # Set to True to save models during and after training\n",
    "MODEL_SAVE_DIR = 'saved_models'  # Directory to save models\n",
    "SAVE_BEST_ONLY = True  # Save only the best model (based on test accuracy) during training\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8744157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "# Use relative path that works across different machines\n",
    "import os\n",
    "# Get project root (parent of notebooks directory)\n",
    "current_dir = os.getcwd()\n",
    "if 'notebooks' in current_dir:\n",
    "    project_root = os.path.dirname(current_dir)\n",
    "else:\n",
    "    # If running from project root\n",
    "    project_root = current_dir\n",
    "custom_path = os.path.join(project_root, 'mnist_dataset')\n",
    "# Fallback to absolute path if relative doesn't work\n",
    "if not os.path.exists(custom_path):\n",
    "    custom_path = '/Users/shreyasavant/Desktop/comp6721/project_git_speed/project/mnist_dataset'\n",
    "    if not os.path.exists(custom_path):\n",
    "        print(f\"Warning: Dataset path not found. Using: {custom_path}\")\n",
    "        print(\"Please update the custom_path variable if needed.\")\n",
    "\n",
    "# load the data\n",
    "train_dataset = DataClass(split='train', transform=data_transform, download=download, root=custom_path, size=224, mmap_mode='r')\n",
    "test_dataset = DataClass(split='test', transform=data_transform, download=download, root=custom_path, size=224, mmap_mode='r')\n",
    "\n",
    "# encapsulate data into dataloader form\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49488583",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_dataset[0]\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb3717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.montage(length=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7a061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL SETUP: CNN (ResNet18) and Swin Transformer\n",
    "# Both using ImageNet pretrained weights and same training approach\n",
    "\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from transformers import SwinModel\n",
    "\n",
    "# Check for CUDA availability and set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Number of channels: {n_channels}\")\n",
    "print(f\"Number of classes: {n_classes}\")\n",
    "print(f\"Using pretrained weights: {USE_PRETRAINED}\")\n",
    "\n",
    "# CNN Model: ResNet18 with ImageNet pretrained weights\n",
    "\n",
    "if USE_PRETRAINED:\n",
    "    # New torchvision API - load pretrained model with weights\n",
    "    weights = ResNet18_Weights.IMAGENET1K_V1\n",
    "    cnn_model = resnet18(weights=weights).to(device)\n",
    "    # Replace the final fully connected layer for our number of classes\n",
    "    num_features = cnn_model.fc.in_features\n",
    "    cnn_model.fc = nn.Linear(num_features, n_classes)\n",
    "    cnn_model = cnn_model.to(device)\n",
    "    print(\"âœ“ CNN: Loaded ResNet18 with ImageNet pretrained weights (IMAGENET1K_V1)\")\n",
    "    print(f\"  Replaced final layer: {num_features} -> {n_classes} classes\")\n",
    "else:\n",
    "    cnn_model = resnet18(weights=None).to(device)\n",
    "    num_features = cnn_model.fc.in_features\n",
    "    cnn_model.fc = nn.Linear(num_features, n_classes)\n",
    "    cnn_model = cnn_model.to(device)\n",
    "    print(\"âœ“ CNN: ResNet18 initialized from scratch\")\n",
    "\n",
    "print(f\"  CNN first layer expects: {cnn_model.conv1.in_channels} channels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2006397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL SAVING UTILITIES\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def setup_model_save_dir(base_dir=MODEL_SAVE_DIR):\n",
    "    \"\"\"Create directory for saving models if it doesn't exist\"\"\"\n",
    "    if SAVE_MODELS:\n",
    "        os.makedirs(base_dir, exist_ok=True)\n",
    "        print(f\"âœ“ Model save directory: {os.path.abspath(base_dir)}\")\n",
    "    return base_dir\n",
    "\n",
    "def save_model_checkpoint(model, model_name, epoch, test_accuracy, save_dir, is_best=False):\n",
    "    \"\"\"Save model checkpoint (best and latest)\"\"\"\n",
    "    if not SAVE_MODELS:\n",
    "        return None\n",
    "    \n",
    "    # Create model name without spaces for filename\n",
    "    model_name_clean = model_name.replace(' ', '_').replace('(', '').replace(')', '').lower()\n",
    "    \n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'model_name': model_name\n",
    "    }\n",
    "    \n",
    "    # Always save latest checkpoint\n",
    "    latest_path = os.path.join(save_dir, f'{model_name_clean}_latest.pt')\n",
    "    torch.save(checkpoint, latest_path)\n",
    "    \n",
    "    # Save best checkpoint if this is the best model\n",
    "    if is_best:\n",
    "        best_path = os.path.join(save_dir, f'{model_name_clean}_best.pt')\n",
    "        torch.save(checkpoint, best_path)\n",
    "        print(f\"  ðŸ’¾ Saved best model checkpoint: {best_path} (Test Acc: {test_accuracy:.2f}%)\")\n",
    "        return best_path\n",
    "    \n",
    "    return latest_path\n",
    "\n",
    "def load_model_checkpoint(model, checkpoint_path, device):\n",
    "    \"\"\"Load model from checkpoint\"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"âœ“ Loaded model from {checkpoint_path}\")\n",
    "    print(f\"  Epoch: {checkpoint['epoch']}, Test Accuracy: {checkpoint.get('test_accuracy', 'N/A')}\")\n",
    "    return checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bf5ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swin Transformer Model: Swin Transformer with ImageNet pretrained weights\n",
    "\n",
    "class SwinTransformerClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, model_name=\"microsoft/swin-base-patch4-window7-224\"):\n",
    "        super().__init__()\n",
    "        if USE_PRETRAINED:\n",
    "            self.swin = SwinModel.from_pretrained(model_name)\n",
    "            print(f\"âœ“ Swin Transformer: Loaded {model_name} with ImageNet pretrained weights\")\n",
    "        else:\n",
    "            # Initialize from config without pretrained weights\n",
    "            from transformers import SwinConfig\n",
    "            config = SwinConfig.from_pretrained(model_name)\n",
    "            self.swin = SwinModel(config)\n",
    "            print(f\"âœ“ Swin Transformer: Initialized {model_name} from scratch\")\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(self.swin.config.hidden_size, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        outputs = self.swin(pixel_values=x)\n",
    "        # Get pooled output (Swin Transformer uses pooler_output)\n",
    "        if hasattr(outputs, 'pooler_output') and outputs.pooler_output is not None:\n",
    "            pooled_output = outputs.pooler_output\n",
    "        else:\n",
    "            # Fallback: use mean pooling of last hidden state\n",
    "            pooled_output = outputs.last_hidden_state.mean(dim=1)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "swin_model = SwinTransformerClassifier(num_classes=n_classes).to(device)\n",
    "print(f\"  Swin Transformer hidden size: {swin_model.swin.config.hidden_size}\")\n",
    "\n",
    "# Loss function and optimizer - same for both models\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Use same optimizer settings for both models (SGD with momentum)\n",
    "# This ensures fair comparison between CNN and Swin Transformer\n",
    "cnn_optimizer = optim.SGD(cnn_model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "swin_optimizer = optim.SGD(swin_model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "print(f\"\\nâœ“ Both models use SGD optimizer with lr={lr}, momentum=0.9, weight_decay=1e-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7322dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIFIED TRAINING FUNCTION - Same approach for both CNN and Swin Transformer\n",
    "\n",
    "def train_model(model, optimizer, model_name, train_loader, test_loader, num_epochs, device, task, criterion):\n",
    "    \"\"\"\n",
    "    Unified training function that works for both CNN and Swin Transformer models.\n",
    "    Uses the same training approach for fair comparison.\n",
    "    \"\"\"\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        model.train()\n",
    "        for inputs, targets in tqdm(train_loader, desc=f\"{model_name} Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "            # Move inputs and targets to device\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Handle different task types\n",
    "            if task == 'multi-label, binary-class':\n",
    "                targets = targets.to(torch.float32)\n",
    "                loss = criterion(outputs, targets)\n",
    "                pred = (torch.sigmoid(outputs) > 0.5).int()\n",
    "                train_correct += (pred == targets.int()).all(dim=1).sum().item()\n",
    "            else:\n",
    "                targets = targets.squeeze().long()\n",
    "                loss = criterion(outputs, targets)\n",
    "                _, pred = torch.max(outputs, 1)\n",
    "                train_correct += (pred == targets).sum().item()\n",
    "            \n",
    "            # Backward pass\n",
    "            train_loss += loss.item()\n",
    "            train_total += targets.size(0)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Calculate training metrics\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_accuracy = 100.0 * train_correct / train_total\n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        test_loss = 0.0\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(test_loader, desc=f\"{model_name} Epoch {epoch+1}/{num_epochs} [Test]\"):\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                if task == 'multi-label, binary-class':\n",
    "                    targets = targets.to(torch.float32)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    pred = (torch.sigmoid(outputs) > 0.5).int()\n",
    "                    test_correct += (pred == targets.int()).all(dim=1).sum().item()\n",
    "                else:\n",
    "                    targets = targets.squeeze().long()\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    _, pred = torch.max(outputs, 1)\n",
    "                    test_correct += (pred == targets).sum().item()\n",
    "                \n",
    "                test_loss += loss.item()\n",
    "                test_total += targets.size(0)\n",
    "        \n",
    "        # Calculate test metrics\n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "        test_accuracy = 100.0 * test_correct / test_total\n",
    "        test_losses.append(avg_test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f'\\n{model_name} - Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.2f}%')\n",
    "        print(f'  Test Loss: {avg_test_loss:.4f}, Test Acc: {test_accuracy:.2f}%')\n",
    "        print('-' * 50)\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'test_losses': test_losses,\n",
    "        'test_accuracies': test_accuracies\n",
    "    }\n",
    "\n",
    "\n",
    "# TRAIN CNN MODEL\n",
    "\n",
    "if 'device' not in locals():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "cnn_history = train_model(\n",
    "    model=cnn_model,\n",
    "    optimizer=cnn_optimizer,\n",
    "    model_name=\"CNN (ResNet18)\",\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    device=device,\n",
    "    task=task,\n",
    "    criterion=criterion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67bf1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE FINAL MODELS (Optional - models are already saved as checkpoints)\n",
    "\n",
    "if SAVE_MODELS:\n",
    "    model_save_dir = setup_model_save_dir()\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Saving Final Models\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Save final CNN model with full training history\n",
    "    cnn_final_path = os.path.join(model_save_dir, 'cnn_resnet18_final.pt')\n",
    "    torch.save({\n",
    "        'model_state_dict': cnn_model.state_dict(),\n",
    "        'model_name': 'CNN (ResNet18)',\n",
    "        'num_classes': n_classes,\n",
    "        'final_test_accuracy': cnn_history.get('best_test_accuracy', cnn_history['test_accuracies'][-1]),\n",
    "        'best_epoch': cnn_history.get('best_epoch', NUM_EPOCHS),\n",
    "        'training_history': cnn_history,\n",
    "        'hyperparameters': {\n",
    "            'num_epochs': NUM_EPOCHS,\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'learning_rate': lr,\n",
    "            'use_pretrained': USE_PRETRAINED\n",
    "        }\n",
    "    }, cnn_final_path)\n",
    "    print(f\"âœ“ Saved final CNN model: {cnn_final_path}\")\n",
    "    \n",
    "    # Save final Swin Transformer model with full training history\n",
    "    swin_final_path = os.path.join(model_save_dir, 'swin_transformer_final.pt')\n",
    "    torch.save({\n",
    "        'model_state_dict': swin_model.state_dict(),\n",
    "        'model_name': 'Swin Transformer',\n",
    "        'num_classes': n_classes,\n",
    "        'final_test_accuracy': swin_history.get('best_test_accuracy', swin_history['test_accuracies'][-1]),\n",
    "        'best_epoch': swin_history.get('best_epoch', NUM_EPOCHS),\n",
    "        'training_history': swin_history,\n",
    "        'hyperparameters': {\n",
    "            'num_epochs': NUM_EPOCHS,\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'learning_rate': lr,\n",
    "            'use_pretrained': USE_PRETRAINED\n",
    "        }\n",
    "    }, swin_final_path)\n",
    "    print(f\"âœ“ Saved final Swin Transformer model: {swin_final_path}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"All models saved to: {os.path.abspath(model_save_dir)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(\"\\nSaved files:\")\n",
    "    print(\"  CNN:\")\n",
    "    print(\"    - cnn_resnet18_best.pt (best checkpoint during training)\")\n",
    "    print(\"    - cnn_resnet18_latest.pt (latest checkpoint)\")\n",
    "    print(\"    - cnn_resnet18_final.pt (final model with full history)\")\n",
    "    print(\"  Swin Transformer:\")\n",
    "    print(\"    - swin_transformer_best.pt (best checkpoint during training)\")\n",
    "    print(\"    - swin_transformer_latest.pt (latest checkpoint)\")\n",
    "    print(\"    - swin_transformer_final.pt (final model with full history)\")\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"To load a saved model later, use:\")\n",
    "    print(\"  checkpoint = torch.load('saved_models/cnn_resnet18_best.pt', map_location=device)\")\n",
    "    print(\"  model.load_state_dict(checkpoint['model_state_dict'])\")\n",
    "    print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64489b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUICK SAVE: Save any model currently in memory\n",
    "# Use this cell to save a model that's already trained and in memory\n",
    "\n",
    "def quick_save_model(model, model_name, save_path=None, additional_info=None):\n",
    "    \"\"\"\n",
    "    Quickly save a model that's currently in memory.\n",
    "    \n",
    "    Args:\n",
    "        model: The PyTorch model to save\n",
    "        model_name: Name/description of the model\n",
    "        save_path: Full path to save the model (optional, defaults to saved_models/)\n",
    "        additional_info: Dictionary with any additional info to save (optional)\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    # Setup save directory\n",
    "    if save_path is None:\n",
    "        os.makedirs('saved_models', exist_ok=True)\n",
    "        model_name_clean = model_name.replace(' ', '_').replace('(', '').replace(')', '').lower()\n",
    "        save_path = os.path.join('saved_models', f'{model_name_clean}_manual_save.pt')\n",
    "    \n",
    "    # Prepare checkpoint\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'model_name': model_name,\n",
    "        'num_classes': n_classes if 'n_classes' in globals() else None,\n",
    "    }\n",
    "    \n",
    "    # Add any additional info\n",
    "    if additional_info:\n",
    "        checkpoint.update(additional_info)\n",
    "    \n",
    "    # Save the model\n",
    "    torch.save(checkpoint, save_path)\n",
    "    print(f\"âœ“ Model saved successfully!\")\n",
    "    print(f\"  Path: {os.path.abspath(save_path)}\")\n",
    "    print(f\"  Model: {model_name}\")\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "# Example usage (uncomment and modify as needed):\n",
    "# \n",
    "# # Save CNN model:\n",
    "# quick_save_model(\n",
    "#     model=cnn_model,\n",
    "#     model_name=\"CNN (ResNet18) - Manual Save\",\n",
    "#     additional_info={'test_accuracy': 85.5}  # optional\n",
    "# )\n",
    "#\n",
    "# # Save Swin Transformer model:\n",
    "# quick_save_model(\n",
    "#     model=swin_model,\n",
    "#     model_name=\"Swin Transformer - Manual Save\",\n",
    "#     additional_info={'test_accuracy': 87.2}  # optional\n",
    "# )\n",
    "#\n",
    "# # Or save to a specific path:\n",
    "# quick_save_model(\n",
    "#     model=cnn_model,\n",
    "#     model_name=\"My Custom Model\",\n",
    "#     save_path='my_custom_path/model.pt'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151c5df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN SWIN TRANSFORMER MODEL\n",
    "\n",
    "swin_history = train_model(\n",
    "    model=swin_model,\n",
    "    optimizer=swin_optimizer,\n",
    "    model_name=\"Swin Transformer\",\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    device=device,\n",
    "    task=task,\n",
    "    criterion=criterion\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8511746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE BOTH MODELS USING MEDMNIST EVALUATOR\n",
    "\n",
    "def evaluate_model_medmnist(model, model_name, data_loader, split, device, task):\n",
    "    \"\"\"Evaluate model and return metrics using medmnist Evaluator\"\"\"\n",
    "    model.eval()\n",
    "    y_true = torch.tensor([])\n",
    "    y_score = torch.tensor([])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.softmax(dim=-1)\n",
    "            \n",
    "            # Collect both y_true and y_score\n",
    "            y_score = torch.cat((y_score, outputs.cpu()), 0)\n",
    "            # Handle targets shape (might be (batch_size, 1) or (batch_size,))\n",
    "            if targets.dim() > 1:\n",
    "                targets = targets.squeeze()\n",
    "            y_true = torch.cat((y_true, targets.cpu()), 0)\n",
    "    \n",
    "    y_score = y_score.detach().numpy()\n",
    "    y_true = y_true.detach().numpy()\n",
    "    \n",
    "    evaluator = Evaluator(data_flag, split, size=224)\n",
    "    try:\n",
    "        metrics = evaluator.evaluate(y_score, y_true)\n",
    "    except TypeError:\n",
    "        metrics = evaluator.evaluate(y_score)\n",
    "    \n",
    "    print(f'\\n{model_name} - {split.upper()} Results:')\n",
    "    print(f'  AUC: {metrics[0]:.3f}, Accuracy: {metrics[1]:.3f}')\n",
    "    return metrics\n",
    "\n",
    "split = 'test'\n",
    "data_loader = train_loader if split == 'train' else test_loader\n",
    "\n",
    "# Evaluate CNN\n",
    "cnn_metrics = evaluate_model_medmnist(cnn_model, \"CNN (ResNet18)\", data_loader, split, device, task)\n",
    "\n",
    "# Evaluate Swin Transformer\n",
    "swin_metrics = evaluate_model_medmnist(swin_model, \"Swin Transformer\", data_loader, split, device, task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e54913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT COMPARISON: CNN vs Swin Transformer Training Curves\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Loss plots\n",
    "axes[0, 0].plot(range(1, NUM_EPOCHS + 1), cnn_history['train_losses'], 'b-', label='CNN Train', linewidth=2)\n",
    "axes[0, 0].plot(range(1, NUM_EPOCHS + 1), cnn_history['test_losses'], 'b--', label='CNN Test', linewidth=2)\n",
    "axes[0, 0].plot(range(1, NUM_EPOCHS + 1), swin_history['train_losses'], 'r-', label='Swin Train', linewidth=2)\n",
    "axes[0, 0].plot(range(1, NUM_EPOCHS + 1), swin_history['test_losses'], 'r--', label='Swin Test', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training and Test Loss Comparison')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Accuracy plots\n",
    "axes[0, 1].plot(range(1, NUM_EPOCHS + 1), cnn_history['train_accuracies'], 'b-', label='CNN Train', linewidth=2)\n",
    "axes[0, 1].plot(range(1, NUM_EPOCHS + 1), cnn_history['test_accuracies'], 'b--', label='CNN Test', linewidth=2)\n",
    "axes[0, 1].plot(range(1, NUM_EPOCHS + 1), swin_history['train_accuracies'], 'r-', label='Swin Train', linewidth=2)\n",
    "axes[0, 1].plot(range(1, NUM_EPOCHS + 1), swin_history['test_accuracies'], 'r--', label='Swin Test', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "axes[0, 1].set_title('Training and Test Accuracy Comparison')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# CNN only\n",
    "axes[1, 0].plot(range(1, NUM_EPOCHS + 1), cnn_history['train_losses'], 'b-', label='Train Loss', linewidth=2)\n",
    "axes[1, 0].plot(range(1, NUM_EPOCHS + 1), cnn_history['test_losses'], 'r-', label='Test Loss', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Loss')\n",
    "axes[1, 0].set_title('CNN (ResNet18) - Loss')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Swin Transformer only\n",
    "axes[1, 1].plot(range(1, NUM_EPOCHS + 1), swin_history['train_losses'], 'b-', label='Train Loss', linewidth=2)\n",
    "axes[1, 1].plot(range(1, NUM_EPOCHS + 1), swin_history['test_losses'], 'r-', label='Test Loss', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Loss')\n",
    "axes[1, 1].set_title('Swin Transformer - Loss')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# FINAL RESULTS SUMMARY\n",
    "\n",
    "print(f'\\n{'='*60}')\n",
    "print('FINAL RESULTS SUMMARY')\n",
    "print(f'{'='*60}')\n",
    "\n",
    "print(f'\\nCNN (ResNet18) Results:')\n",
    "print(f'  Best Train Accuracy: {max(cnn_history[\"train_accuracies\"]):.2f}%')\n",
    "print(f'  Best Test Accuracy: {max(cnn_history[\"test_accuracies\"]):.2f}%')\n",
    "print(f'  Final Train Loss: {cnn_history[\"train_losses\"][-1]:.4f}')\n",
    "print(f'  Final Test Loss: {cnn_history[\"test_losses\"][-1]:.4f}')\n",
    "print(f'  MedMNIST Test AUC: {cnn_metrics[0]:.3f}, Acc: {cnn_metrics[1]:.3f}')\n",
    "\n",
    "print(f'\\nSwin Transformer Results:')\n",
    "print(f'  Best Train Accuracy: {max(swin_history[\"train_accuracies\"]):.2f}%')\n",
    "print(f'  Best Test Accuracy: {max(swin_history[\"test_accuracies\"]):.2f}%')\n",
    "print(f'  Final Train Loss: {swin_history[\"train_losses\"][-1]:.4f}')\n",
    "print(f'  Final Test Loss: {swin_history[\"test_losses\"][-1]:.4f}')\n",
    "print(f'  MedMNIST Test AUC: {swin_metrics[0]:.3f}, Acc: {swin_metrics[1]:.3f}')\n",
    "\n",
    "print(f'\\n{'='*60}')\n",
    "print('TRAINING CONFIGURATION:')\n",
    "print(f'  Both models use ImageNet pretrained weights: {USE_PRETRAINED}')\n",
    "print(f'  Optimizer: SGD with lr={lr}, momentum=0.9, weight_decay=1e-4')\n",
    "print(f'  Batch size: {BATCH_SIZE}')\n",
    "print(f'  Epochs: {NUM_EPOCHS}')\n",
    "print(f'  Loss function: CrossEntropyLoss')\n",
    "print(f'{'='*60}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e56ed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT TRAINING AND TESTING ACCURACY CURVES\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure with two subplots - one for each model\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# CNN Accuracy Curves\n",
    "axes[0].plot(range(1, NUM_EPOCHS + 1), cnn_history['train_accuracies'], 'b-o', \n",
    "             label='Training Accuracy', linewidth=2, markersize=8)\n",
    "axes[0].plot(range(1, NUM_EPOCHS + 1), cnn_history['test_accuracies'], 'r-s', \n",
    "             label='Testing Accuracy', linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[0].set_title('CNN (ResNet18) - Training and Testing Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xticks(range(1, NUM_EPOCHS + 1))\n",
    "\n",
    "# Swin Transformer Accuracy Curves\n",
    "axes[1].plot(range(1, NUM_EPOCHS + 1), swin_history['train_accuracies'], 'b-o', \n",
    "             label='Training Accuracy', linewidth=2, markersize=8)\n",
    "axes[1].plot(range(1, NUM_EPOCHS + 1), swin_history['test_accuracies'], 'r-s', \n",
    "             label='Testing Accuracy', linewidth=2, markersize=8)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[1].set_title('Swin Transformer - Training and Testing Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xticks(range(1, NUM_EPOCHS + 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print accuracy summary\n",
    "print(f'\\n{\"=\"*60}')\n",
    "print('ACCURACY SUMMARY')\n",
    "print(f'{\"=\"*60}')\n",
    "print(f'\\nCNN (ResNet18):')\n",
    "print(f'  Training Accuracy: {cnn_history[\"train_accuracies\"][-1]:.2f}% (Final), {max(cnn_history[\"train_accuracies\"]):.2f}% (Best)')\n",
    "print(f'  Testing Accuracy:  {cnn_history[\"test_accuracies\"][-1]:.2f}% (Final), {max(cnn_history[\"test_accuracies\"]):.2f}% (Best)')\n",
    "print(f'\\nSwin Transformer:')\n",
    "print(f'  Training Accuracy: {swin_history[\"train_accuracies\"][-1]:.2f}% (Final), {max(swin_history[\"train_accuracies\"]):.2f}% (Best)')\n",
    "print(f'  Testing Accuracy:  {swin_history[\"test_accuracies\"][-1]:.2f}% (Final), {max(swin_history[\"test_accuracies\"]):.2f}% (Best)')\n",
    "print(f'{\"=\"*60}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
